# @package model

type: llm

model_name: meta-llama/Meta-Llama-3.1-8B
model_tag: llama3.1-8B

training_args:
  max_len: 256
  batch_size: 4
  lr: 2e-4
  n_epochs: 3

lora:
  alpha: 16
  dropout: 0.1
  r: 64

peft_config:
  task_type: SEQ_CLS
  bias: none
  4bit:
    load_in_4bit: True
    bnb_4bit_use_double_quant: True
    bnb_4bit_quant_type: nf4
    bnb_4bit_compute_dtype: torch.bfloat16
  
text_representation: raw